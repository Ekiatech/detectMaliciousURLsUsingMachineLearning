{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "from pyspark.sql import SparkSession, functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation SparkSession\n",
    "\n",
    "# Créer un objet SparkSession\n",
    "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des donnees\n",
    "\n",
    "# Charger les données à partir d'un fichier CSV\n",
    "data = spark.read.csv(\"urldata.csv\", header=True, inferSchema=True)\n",
    "\n",
    "data = data.select([\"URLs\", \"Class\"])\n",
    "# convert the Class column to a numeric type\n",
    "data = data.withColumn(\"Class\", functions.when(data[\"Class\"] == \"benign\", 0)\n",
    "                                         .otherwise(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout de critères au dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Calculer la longueur du texte dans la colonne \"Text\"\n",
    "data = data.withColumn(\"url_length\", F.length(\"URLs\"))\n",
    "data = data.withColumn(\"count-dir\", F.size(F.split(F.col(\"URLs\"), r\"/\")) - 3)\n",
    "data = data.withColumn(\"count-digits\", F.size(F.split(F.col(\"URLs\"), r\"\\d\")) - 1)\n",
    "data = data.withColumn(\"count-points\", F.size(F.split(F.col(\"URLs\"), r\"\\.\")) - 1)\n",
    "data = data.withColumn(\"count-\", F.size(F.split(F.col(\"URLs\"), r\"\\-\")) - 1)\n",
    "data = data.withColumn(\"count_\", F.size(F.split(F.col(\"URLs\"), r\"\\_\")) - 1)\n",
    "data = data.withColumn(\"count@\", F.size(F.split(F.col(\"URLs\"), r\"\\@\")) - 1)\n",
    "data = data.withColumn(\"count?\", F.size(F.split(F.col(\"URLs\"), r\"\\?\")) - 1)\n",
    "data = data.withColumn(\"count%\", F.size(F.split(F.col(\"URLs\"), r\"\\%\")) - 1)\n",
    "data = data.withColumn(\"count=\", F.size(F.split(F.col(\"URLs\"), r\"\\=\")) - 1)\n",
    "data = data.withColumn(\"count-http\", F.size(F.split(F.col(\"URLs\"), r\"http\")) - 1)\n",
    "data = data.withColumn(\"count-https\", F.size(F.split(F.col(\"URLs\"), r\"https\")) - 1)\n",
    "data = data.withColumn(\"count-www\", F.size(F.split(F.col(\"URLs\"), r\"www\")) - 1)\n",
    "\n",
    "data = data.withColumn(\"target\", F.lit(0))\n",
    "\n",
    "data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import NaiveBayes \n",
    "\n",
    "# Diviser les données en deux ensembles aléatoires\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Afficher le nombre de partitions utilisées pour distribuer les données\n",
    "num_partitions = train_data.rdd.getNumPartitions()\n",
    "print(num_partitions)\n",
    "\n",
    "input_cols = ['count-digits', \n",
    "                'count-dir', \n",
    "                'count-points', \n",
    "                'count-', \n",
    "                'count_', \n",
    "                'count@', \n",
    "                'count?', \n",
    "                'count%',\n",
    "                'count=', \n",
    "                'count-http', \n",
    "                'count-https', \n",
    "                'count-www', \n",
    "                'url_length'\n",
    "                ]\n",
    "\n",
    "# Sélectionner les colonnes \"length\" et \"question_marks\" comme entrées pour le modèle\n",
    "assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n",
    "\n",
    "# Créer un objet NaiveBayes\n",
    "mnb = NaiveBayes(labelCol=\"Class\", featuresCol=\"features\")\n",
    "\n",
    "# Définir les paramètres du modèle de régression logistique\n",
    "lr = LogisticRegression(labelCol=\"Class\", featuresCol=\"features\", maxIter=150, regParam=0.1)\n",
    "\n",
    "# Créer un objet RandomForestClassifier\n",
    "rfc = RandomForestClassifier(labelCol=\"Class\", featuresCol=\"features\")\n",
    "\n",
    "# Combiner les étapes d'assemblage des vecteurs et de régression logistique en un seul pipeline\n",
    "pipeline = Pipeline(stages=[assembler, mnb])\n",
    "\n",
    "# Entraîner le modèle sur les données d'entrée\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Utiliser le modèle entraîné pour prédire des étiquettes de sortie pour les données de test\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Définir les paramètres d'évaluation du modèle\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Class\", predictionCol=\"prediction\")\n",
    "\n",
    "# Évaluer le modèle en utilisant les données d'entrée et les étiquettes de sortie prédites\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "\n",
    "# Afficher l'accuracy du modèle\n",
    "print(accuracy)\n",
    "print(f1)\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "predictions.groupBy(\"Class\", \"prediction\").count().show()\n",
    "\n",
    "# Afficher les prédictions en utilisant un diagramme à barres\n",
    "predictions.select(\"Class\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec l'utilisation d'un tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Décomposer les URL en mots individuels\n",
    "tokenizer = Tokenizer(inputCol=\"URLs\", outputCol=\"words\")\n",
    "data = tokenizer.transform(data)\n",
    "\n",
    "# Compter le nombre d'occurrences de chaque mot\n",
    "counter = CountVectorizer(inputCol=\"words\", outputCol=\"features\")\n",
    "data = counter.fit(data).transform(data)\n",
    "\n",
    "# Diviser les données en deux ensembles aléatoires\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Sélectionner les colonnes d'entrée et de sortie\n",
    "train_input = train_data.select(\"features\", \"Class\")\n",
    "train_output = train_data.select(\"Class\")\n",
    "\n",
    "# Entraîner un modèle de forêts aléatoires\n",
    "#rf = RandomForestClassifier(labelCol=\"Class\", featuresCol=\"features\", maxDepth=3, numTrees=2)\n",
    "lr = LogisticRegression(labelCol=\"Class\", featuresCol=\"features\")\n",
    "\n",
    "model = lr.fit(train_input)\n",
    "\n",
    "# Utiliser le modèle pour faire des prédictions sur les données de test\n",
    "test_input = test_data.select(\"features\", \"Class\")\n",
    "predictions = model.transform(test_input)\n",
    "\n",
    "# Calculer l'erreur de classification\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Class\", predictionCol=\"prediction\")\n",
    "\n",
    "# Afficher les résultats de l'évaluation\n",
    "print(\"Accuracy = %g\" % evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"}))\n",
    "print(\"F1-Score = %g\" % evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"}))\n",
    "\n",
    "# Afficher les prédictions en utilisant un diagramme à barres\n",
    "predictions.select(\"Class\", \"prediction\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
